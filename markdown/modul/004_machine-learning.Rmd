---
title: "Modul 4: Machine Learning"
author: "Big Data and Business Analytics Laboratory, SBM-ITB"
output:
    theme: architect
    highlight: github
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
# Set Knit
knitr::opts_chunk$set(tidy.opts = list(width.cutoff = 60), tidy = TRUE)
```

Di praktek kali ini kita akan belajar membuat model machine learning untuk memprediksi apakah seorang nasabah akan berlangganan Deposito Berjangka (Term Deposit) menggunakan Bank Marketing Dataset seperti yang sudah kita gunakan di modul-modul sebelumnya. Seperti yang sudah dijelaskan sebelumnya, bahwa dataset bank marketing ini berisikan informasi terkait Marketing Campaign sebuah Bank di Portugis. Marketing Campaign ini bertujuan untuk menawarkan deposito berjangka (Deposito Jangka Panjang) kepada para nasabah. 

## Load Package
Pada praktek-praktek sebelumnya, teman-teman sudah belajar berbagai tipe Package seperti ```dplyr```, ```readr```, ```ggplot```. Package-Package tersebut sebenarnya merupakan bagian dari Package dengan nama ```tidyverse```. Package tidyverse merupakan kumpulan Package-Package untuk melakukan proses data science, mulai dari mengimport data hingga melakukan visualisasi. Dengan meload Package ```tidyverse``` kita secara otomatis juga mengaktifkan Package-Package yang ada didalamnya, termasuk ```dplyr```, ```readr```, ```ggplot```. Untuk melihat Package apa saja yang termasuk di Package tidyverse teman-teman dapat melihatnya di dokumentasi tidyverse. 

Selain Package ```tidyverse```, kita juga memerlukan Package ```tidymodels``` yang berfungsi untuk membantu kita dalam membuat alur/workflow model machine learning, Package ```discrim``` untuk model analisis discriminant, dan Package ```naivebayes``` untuk memodelkan dengan algoritma Naive Bayes. Mari kita insall dan load Package-Package tersebut terlebih dahulu. 

```{r}
# Install package
install.packages(c("tidyverse", "tidymodels", "discrim", "naivebayes"))
```

```{r}
# Load package
library(tidyverse)
library(tidymodels)
library(discrim)
library(naivebayes)
```

## Import Data
Sebelum memulai mari kita import datanya terlebih dahulu. 

```{r}
# Import Data
df <- read_csv2("data/raw/bank-marketing.csv")
```

Setelah diimport, kita dapat melihat seperti apa data kita menggunakan fungsi ```head()``` untuk menampilkan beberapa baris pertama data, atau menggunakan fungsi ```glimpse()```

```{r}
# Meampilkan 5 baris pertama data
head(df)
```

```{r}
# menampilkan rangkuman data menggunakan fungsi glimpse()
glimpse(df)
```
Pada umumnya setelah data diimport, tahapan yang dilakukan adalah EDA atau Exploratory Data Analysis, yang bertujuan untuk mencari insight awal terkait data kita. Namun, di praktek kali ini kita akan mengsumsikan bahwa data kita sudah cukup baik untuk dimodelkan, dan kita juga sudah cukup memliki insight terkait data pada saat praktik-praktik sebelumnya.  

## Split Data
Sebelum dimodelkan, data harus dibagi menjadi dua yaitu data train untuk membuat model, dan data test untuk menguji performa model. Umumnya, data dibagi dengan proporsi 70% train dan 30% test.

```{r}
# Set Seed
set.seed(1234)
```

```{r}
# Membagi data dengan proporsi 70:30
df_split <- initial_split(df, prop = 0.8)
df_split
```

```{r}
# Menampilkan data training
df_split %>%
  training() %>%
  glimpse()
```

## Membut Alur Pemrosesan Data
Setelah membagi data kedalam training dan testing, kita dapat membuat alur pemrosesan data. Disini menenetukan role masing-masing variable, seperti menentukan variable yang akan diprediksi, dan yang memprediksi. Di alur pemrosesan data ini kita juga dapat menambah proses untuk meningkatkan kualitas data kita seperti mengisi nilai data yang kosong, normalisasi, down sampling, dan sebagainya. 

```{r}
# Membuat Recipe
df_recipe <- training(df_split) %>%
  recipe(y ~.) %>%
  prep()

df_recipe
```

Untuk melihat bagaimana hasil pemrosesan ini pada data traning kita. Kita dapat menggunakan fungsi ```juice()```.

```{r}
# Mererapkan ke data training 
df_training <- juice(df_recipe)
glimpse(df_training)
```
Jika sudah sesuai, kita dapat menerapkan kedalam data testing menggunakan fungsi ```bake```.

```{r}
# Menerapkan ke data testing
df_testing <- df_recipe %>%
  bake(testing(df_split)) 

glimpse(df_testing)
```
## Menentukan Algoritma
Tahap selanjutnya adalah menetukan algoritma apa yang akan kita gunakan untuk melakukan prediksi klasifikasi. Di modul ini kita akan menggunakan algoritma naive bayes

```{r}
# Menset model
nb_mod <-  naive_Bayes(mode = "classification") %>%
  set_engine('naivebayes') 
```

## Membuat Workflow
Jika sudah menentukan alur pemrosesan data, dan algoritma yang akan digunakan, kita dapat menyatukannya kedalam 1 workflow. 

```{r}
# Membuat Workflow
workflow <- workflow() %>%
  add_model(nb_mod) %>%
  add_recipe(df_recipe)
```

## Training dan Prediksi ke data set
Jika workflow sudah sesuai dan berhasil dibuat, kita dapat langsung melakukan proses training dan melakukan prediksi ke data testing.

```{r}
# Training Model
nb <- fit(workflow, training(df_split))

# Prediksi ke data test
head(predict(nb, testing(df_split)))
```

##  Mengukur Performa Model
Tahapan terakhir adalah mengecek seberapa baik model kita dalam melakukan prediksi, dengan membandingkan nilai hasil prediksi model machine learning dengan nilai yang sebenarnya. 

```{r}
# Menentukan metrik evaluasi untuk mengukur performa model
multi_metrics <- metric_set(accuracy, sensitivity, recall, f_meas)

# Melihat performa model
nb %>%
  predict(df_testing) %>%
  bind_cols(df_testing) %>%
  multi_metrics(truth = y, estimate = .pred_class)
```

Dapat kita lihat ternyata model kita memiki akurasi yang cukup baik, yaitu diatas 80%. Begitu juga dengan nilai sensitivity dan recall. 

##  Mengaplikasikan Model ke Data Baru
Langkah akhir dari pembuatan sebuah model adalah, menggunakan model tersebut untuk memprediksi data baru. Disini kita memmiliki data 10 nasabah baru yang belum diketahui, apakah pelanggan tersebut akan berlanganan deposito berjangnka atau tidak. Kita akan menggunakan model yang sudah kita buat tadi untuk memprediksinya. 

Data yangv  akan diprediksi terdapat dai directory "data/raw" dengan nama "bank-marketing_new.csv". 

```{r}
# Import data baru
df_new <- read_csv2("data/raw/bank-marketing_new.csv")
head(df_new)
```

Dapat kita lihat bahwa belum ada kolom yang menyatakan bahwa pelanggan tersebut berlanggan deposito berjangka atu tidak. Untuk melakukan prediksi kita pat langsung menggunakan fungsi ```predict``` ke data baru kita. 

```{r}
# Melakukan prediksi dan menyimpan nilai hasil prediksi
df_predicted <- predict(nb, df_new) %>%
  bind_cols(df_new) %>%
  write_csv("data/predicted/bank-marketing_predicted.csv")

# Menampilkan hasil prediksi
print(df_predicted)
```
d
ari 10 nasabah baru tadi, ternyata ada 4 nasbah yang diprediksi akan berlangganan deposito berjangka. 

```{r}
# Siapa yang akan berlangganan
df_subscribe <- df_predicted %>%
  filter(.pred_class == "yes")

print(df_subscribe)
```

## Praktek
Sekarang teman-teman sudah paham teknik-teknik untuk membuat model machine learning. Sama seperti sebelumnya, saatnya kita meangaplikasikan ke kasus baru. Kita akan menggunakan dataset telco customer churn dataset sama seperti modul-modul sebelumnya. 

```{r}
# Import Customer Churn Dataset
df_churn <- read_csv("data/raw/customer-churn.csv")
```

### Soal
Buatlah model machine learning untuk memprediksi cutomer churn dan lakukan prediksi kepada data baru yaitu data "customer-churn_new.csv" yang ada pada direktori "data/raw". Dari 10 pelanggan baru, berapa yang akan churn?

```{r}
# Jawaban

```

